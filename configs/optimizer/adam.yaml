_target_: torch.optim.Adam
lr: 1e-2  # Initial learning rate
# weight_decay: 0.0  # Weight decay for adam|lamb; should use AdamW instead if desired
betas: [0.9, 0.999]